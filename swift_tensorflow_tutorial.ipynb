{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwxGnsA92emp"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CPII1rGR2rF9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "// you may not use this file except in compliance with the License.\n",
    "// You may obtain a copy of the License at\n",
    "//\n",
    "// https://www.apache.org/licenses/LICENSE-2.0\n",
    "//\n",
    "// Unless required by applicable law or agreed to in writing, software\n",
    "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "// See the License for the specific language governing permissions and\n",
    "// limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swift for TensorFlow is a work-in-progress\n",
    "\n",
    "Swift for TensorFlow is still a work-in-progress. If you modify the code in this tutorial, you will frequently get unexepcted error messages and kernel crashes. Restarting the kernel might occasionally help (Kernel > Restart in the Jupyter toolbar).\n",
    "\n",
    "We are working on stabilizing the compiler. You can help us by filing bugs on https://bugs.swift.org (set the \"Component\" field to \"Swift for TensorFlow\") or by emailing the swift@tensorflow.org mailing list when you encounter unexpected error messages and kernel crashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JtEZ1pCPn--z"
   },
   "source": [
    "# Swift for TensorFlow: walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDrzLFXE8T1l"
   },
   "source": [
    "This guide introduces Swift for TensorFlow by using Swift for TensorFlow to build a machine learning model that categorizes iris flowers by species. It uses Swift for TensorFlow to:\n",
    "1. Build a model,\n",
    "2. Train this model on example data, and\n",
    "3. Use the model to make predictions about unknown data.\n",
    "\n",
    "This guide is a Swift port of the [TensorFlow custom training walkthrough](https://www.tensorflow.org/tutorials/eager/custom_training_walkthrough).\n",
    "\n",
    "## TensorFlow programming\n",
    "\n",
    "This guide uses these high-level Swift for TensorFlow concepts:\n",
    "\n",
    "* Import data with the Datasets API.\n",
    "* Build models and layers using Swift abstractions.\n",
    "* Use Python libraries using Swift's Python interoperability when pure Swift libraries are not available.\n",
    "\n",
    "This tutorial is structured like many TensorFlow programs:\n",
    "\n",
    "1. Import and parse the data sets.\n",
    "2. Select the type of model.\n",
    "3. Train the model.\n",
    "4. Evaluate the model's effectiveness.\n",
    "5. Use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNr7H-AIoLOR"
   },
   "source": [
    "## Setup program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1J3AuPBT9gyR"
   },
   "source": [
    "### Configure imports\n",
    "\n",
    "Import TensorFlow and some useful Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g4Wzg69bnwK2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import TensorFlow\n",
    "\n",
    "import Python\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")\n",
    "let plt = Python.import(\"matplotlib.pyplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zx7wc0LuuxaJ"
   },
   "source": [
    "## The iris classification problem\n",
    "\n",
    "Imagine you are a botanist seeking an automated way to categorize each iris flower you find. Machine learning provides many algorithms to classify flowers statistically. For instance, a sophisticated machine learning program could classify flowers based on photographs. Our ambitions are more modestâ€”we're going to classify iris flowers based on the length and width measurements of their [sepals](https://en.wikipedia.org/wiki/Sepal) and [petals](https://en.wikipedia.org/wiki/Petal).\n",
    "\n",
    "The Iris genus entails about 300 species, but our program will only classify the following three:\n",
    "\n",
    "* Iris setosa\n",
    "* Iris virginica\n",
    "* Iris versicolor\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://www.tensorflow.org/images/iris_three_species.jpg\"\n",
    "         alt=\"Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://commons.wikimedia.org/w/index.php?curid=170298\">Iris setosa</a> (by <a href=\"https://commons.wikimedia.org/wiki/User:Radomil\">Radomil</a>, CC BY-SA 3.0), <a href=\"https://commons.wikimedia.org/w/index.php?curid=248095\">Iris versicolor</a>, (by <a href=\"https://commons.wikimedia.org/wiki/User:Dlanglois\">Dlanglois</a>, CC BY-SA 3.0), and <a href=\"https://www.flickr.com/photos/33397993@N05/3352169862\">Iris virginica</a> (by <a href=\"https://www.flickr.com/photos/33397993@N05\">Frank Mayfield</a>, CC BY-SA 2.0).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "Fortunately, someone has already created a [data set of 120 iris flowers](https://en.wikipedia.org/wiki/Iris_flower_data_set) with the sepal and petal measurements. This is a classic dataset that is popular for beginner machine learning classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Px6KAg0Jowz"
   },
   "source": [
    "## Import and parse the training dataset\n",
    "\n",
    "Download the dataset file and convert it into a structure that can be used by this Swift program.\n",
    "\n",
    "### Download the dataset\n",
    "\n",
    "Download the training dataset file from http://download.tensorflow.org/data/iris_training.csv. We use a Python library to demonstrate Swift's Python interoperability. Swift's Python interoperability makes it easy and natrual to import and use Python libraries from Swift code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "\"iris_training.csv\"\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let urllib = Python.import(\"urllib\")\n",
    "let downloadResult = urllib.urlretrieve(\"http://download.tensorflow.org/data/iris_training.csv\",\n",
    "                                        \"iris_training.csv\")\n",
    "let trainDataFilename = String(downloadResult[0])!\n",
    "trainDataFilename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnX1-aLors4S"
   },
   "source": [
    "### Inspect the data\n",
    "\n",
    "This dataset, `iris_training.csv`, is a plain text file that stores tabular data formatted as comma-separated values (CSV). Let's look a the first 5 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FQvb_JYdrpPm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120,4,setosa,versicolor,virginica\r\n",
      "6.4,2.8,5.6,2.2,2\r\n",
      "5.0,2.3,3.3,1.0,1\r\n",
      "4.9,2.5,4.5,1.7,2\r\n",
      "4.9,3.1,1.5,0.1,0\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let f = Python.open(trainDataFilename)\n",
    "for _ in 0..<5 {\n",
    "    print(Python.next(f).strip())\n",
    "}\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQhzD6P-uBoq"
   },
   "source": [
    "From this view of the dataset, notice the following:\n",
    "\n",
    "1. The first line is a header containing information about the dataset:\n",
    "  * There are 120 total examples. Each example has four features and one of three possible label names. \n",
    "2. Subsequent rows are data records, one *[example](https://developers.google.com/machine-learning/glossary/#example)* per line, where:\n",
    "  * The first four fields are *[features](https://developers.google.com/machine-learning/glossary/#feature)*: these are characteristics of an example. Here, the fields hold float numbers representing flower measurements.\n",
    "  * The last column is the *[label](https://developers.google.com/machine-learning/glossary/#label)*: this is the value we want to predict. For this dataset, it's an integer value of 0, 1, or 2 that corresponds to a flower name.\n",
    "\n",
    "Let's write that out in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9Edhevw7exl6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\r\n",
      "Label: species\r\n"
     ]
    }
   ],
   "source": [
    "let featureNames = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "let labelName = \"species\"\n",
    "let columnNames = featureNames + [labelName]\n",
    "\n",
    "print(\"Features: \\(featureNames)\")\n",
    "print(\"Label: \\(labelName)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCtwLoJhhDNc"
   },
   "source": [
    "Each label is associated with string name (for example, \"setosa\"), but machine learning typically relies on numeric values. The label numbers are mapped to a named representation, such as:\n",
    "\n",
    "* `0`: Iris setosa\n",
    "* `1`: Iris versicolor\n",
    "* `2`: Iris virginica\n",
    "\n",
    "For more information about features and labels, see the [ML Terminology section of the Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sVNlJlUOhkoX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "let classNames = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqPkQExM2Pwt"
   },
   "source": [
    "### Create a Dataset\n",
    "\n",
    "Swift for TensorFlow's Dataset API handles loading data into a model. This is a high-level API for reading data and transforming it into a form used for training. Currently, Swift's Dataset API supports loading data only from CSV files, but we indend to extend it to handle many more types of data, like [TensorFlow's Dataset API](https://www.tensorflow.org/guide/datasets).\n",
    "\n",
    "Use the `Dataset(contentsOfCSVFile:hasHeader:featureColumns:labelColumns:)` initializer to initialize a `Dataset` with training data. Also batch the data into batches using the `.batched()` function.\n",
    "\n",
    "Some temporary limitations in Swift for TensorFlow make dataset initialization a bit unwieldy:\n",
    "\n",
    "* you must initialize your dataset in an inlinable function,\n",
    "* you must never store your dataset in an intermediate variable,\n",
    "* you must `%include \"TutorialDatasetCSVAPI.swift\"` in every Jupyter cell where you initialize a dataset, and\n",
    "* you must copy your dataset initialization function to every Jupyter cell where you use it.\n",
    "\n",
    "We intend to eliminate these limitations soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "public let batchSize = Int64(32)\n",
    "\n",
    "%include \"TutorialDatasetCSVAPI.swift\"\n",
    "@inlinable\n",
    "func trainDataset() -> Dataset<(Tensor<Float>, Tensor<Int32>)> {\n",
    "    return Dataset(\n",
    "        contentsOfCSVFile: trainDataFilename, hasHeader: true,\n",
    "        featureColumns: [0, 1, 2, 3], labelColumns: [4]\n",
    "    ).batched(batchSize)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gB_RSn62c-3G"
   },
   "source": [
    "This returns a `Dataset` of `(features, labels)` pairs, where `feature` is a `Tensor<Float>` with shape `(batchSize, featureColumns.count)` and where `labels` is a `Tensor<Int32>` with shape `(batchSize, labelColumns.count)`\n",
    "\n",
    "These `Dataset` values are iterable. Let's look at the first element of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iDuG94H-C122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "[[6.4, 2.8, 5.6, 2.2], [5.0, 2.3, 3.3, 1.0], [4.9, 2.5, 4.5, 1.7], [4.9, 3.1, 1.5, 0.1], [5.7, 3.8, 1.7, 0.3], [4.4, 3.2, 1.3, 0.2], [5.4, 3.4, 1.5, 0.4], [6.9, 3.1, 5.1, 2.3], [6.7, 3.1, 4.4, 1.4], [5.1, 3.7, 1.5, 0.4], [5.2, 2.7, 3.9, 1.4], [6.9, 3.1, 4.9, 1.5], [5.8, 4.0, 1.2, 0.2], [5.4, 3.9, 1.7, 0.4], [7.7, 3.8, 6.7, 2.2], [6.3, 3.3, 4.7, 1.6], [6.8, 3.2, 5.9, 2.3], [7.6, 3.0, 6.6, 2.1], [6.4, 3.2, 5.3, 2.3], [5.7, 4.4, 1.5, 0.4], [6.7, 3.3, 5.7, 2.1], [6.4, 2.8, 5.6, 2.1], [5.4, 3.9, 1.3, 0.4], [6.1, 2.6, 5.6, 1.4], [7.2, 3.0, 5.8, 1.6], [5.2, 3.5, 1.5, 0.2], [5.8, 2.6, 4.0, 1.2], [5.9, 3.0, 5.1, 1.8], [5.4, 3.0, 4.5, 1.5], [6.7, 3.0, 5.0, 1.7], [6.3, 2.3, 4.4, 1.3], [5.1, 2.5, 3.0, 1.1]]\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%include \"TutorialDatasetCSVAPI.swift\"\n",
    "@inlinable\n",
    "func trainDataset() -> Dataset<(Tensor<Float>, Tensor<Int32>)> {\n",
    "    return Dataset(\n",
    "        contentsOfCSVFile: trainDataFilename, hasHeader: true,\n",
    "        featureColumns: [0, 1, 2, 3], labelColumns: [4]\n",
    "    ).batched(batchSize)\n",
    "}\n",
    "\n",
    "let (firstTrainFeatures, firstTrainLabels) = trainDataset().first()!\n",
    "\n",
    "firstTrainFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E63mArnQaAGz"
   },
   "source": [
    "Notice that like-features are grouped together, or *batched*. Each example row's fields are appended to the corresponding feature array. Change the `batchSize` to set the number of examples stored in these feature arrays.\n",
    "\n",
    "You can start to see some clusters by plotting a few features from the batch, using Python's matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "me5Wn-9FcyyO",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1114430d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "None\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let firstTrainFeaturesTransposed = firstTrainFeatures.transposed()\n",
    "let petalLengths = firstTrainFeaturesTransposed[3].scalars\n",
    "let sepalLengths = firstTrainFeaturesTransposed[0].scalars\n",
    "\n",
    "plt.scatter(petalLengths, sepalLengths, c: firstTrainLabels.array.scalars)\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Sepal length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsaVrtNM3Tx5"
   },
   "source": [
    "## Select the type of model\n",
    "\n",
    "### Why model?\n",
    "\n",
    "A *[model](https://developers.google.com/machine-learning/crash-course/glossary#model)* is a relationship between features and the label.  For the iris classification problem, the model defines the relationship between the sepal and petal measurements and the predicted iris species. Some simple models can be described with a few lines of algebra, but complex machine learning models have a large number of parameters that are difficult to summarize.\n",
    "\n",
    "Could you determine the relationship between the four features and the iris species *without* using machine learning?  That is, could you use traditional programming techniques (for example, a lot of conditional statements) to create a model?  Perhapsâ€”if you analyzed the dataset long enough to determine the relationships between petal and sepal measurements to a particular species. And this becomes difficultâ€”maybe impossibleâ€”on more complicated datasets. A good machine learning approach *determines the model for you*. If you feed enough representative examples into the right machine learning model type, the program will figure out the relationships for you.\n",
    "\n",
    "### Select the model\n",
    "\n",
    "We need to select the kind of model to train. There are many types of models and picking a good one takes experience. This tutorial uses a neural network to solve the iris classification problem. *[Neural networks](https://developers.google.com/machine-learning/glossary/#neural_network)* can find complex relationships between features and the label. It is a highly-structured graph, organized into one or more *[hidden layers](https://developers.google.com/machine-learning/glossary/#hidden_layer)*. Each hidden layer consists of one or more *[neurons](https://developers.google.com/machine-learning/glossary/#neuron)*. There are several categories of neural networks and this program uses a dense, or *[fully-connected neural network](https://developers.google.com/machine-learning/glossary/#fully_connected_layer)*: the neurons in one layer receive input connections from *every* neuron in the previous layer. For example, Figure 2 illustrates a dense neural network consisting of an input layer, two hidden layers, and an output layer:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://www.tensorflow.org/images/custom_estimators/full_network.png\"\n",
    "         alt=\"A diagram of the network architecture: Inputs, 2 hidden layers, and outputs\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 2.</b> A neural network with features, hidden layers, and predictions.<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "When the model from Figure 2 is trained and fed an unlabeled example, it yields three predictions: the likelihood that this flower is the given iris species. This prediction is called *[inference](https://developers.google.com/machine-learning/crash-course/glossary#inference)*. For this example, the sum of the output predictions is 1.0. In Figure 2, this prediction breaks down as: `0.02` for *Iris setosa*, `0.95` for *Iris versicolor*, and `0.03` for *Iris virginica*. This means that the model predictsâ€”with 95% probabilityâ€”that an unlabeled example flower is an *Iris versicolor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W23DIMVPQEBt"
   },
   "source": [
    "### Create a model using Swift abstractions\n",
    "\n",
    "Swift for TensorFlow doesn't yet have high-level model APIs like Keras, so we will build a model from scratch using low-level TensorFlow APIs.\n",
    "\n",
    "We also work around some temporary limitations in the compiler:\n",
    "\n",
    "* You must define the entire model and loss function in a single Jupyter cell in order to train it. This is because Swift's Automatic Differentiation cannot yet take gradients of functions that call functions defined in other Jupyter cells.\n",
    "* There are a few other workarounds described inline in the comments.\n",
    "\n",
    "We indend to eliminate these limitations soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import TensorFlow\n",
    "\n",
    "%include \"TutorialModelHelpers.swift\"\n",
    "\n",
    "// ==== Define a dense neural network layer ====\n",
    "// Let's start by defining a dense neural network layer as a Swift `struct`:\n",
    "\n",
    "struct DenseLayer : ParameterAggregate {\n",
    "    var w: Tensor<Float>\n",
    "    var b: Tensor<Float>\n",
    "    \n",
    "    init(inputSize: Int32, outputSize: Int32) {\n",
    "        w = Tensor(glorotUniform: [inputSize, outputSize])\n",
    "        b = Tensor(zeros: [outputSize])\n",
    "    }\n",
    "}\n",
    "\n",
    "func predictions(for input: Tensor<Float>, using layer: DenseLayer) -> Tensor<Float> {\n",
    "    return input â€¢ layer.w + layer.b\n",
    "}\n",
    "\n",
    "// The `ParameterAggregate` in the `DenseLayer` declaration tells Swift that that `DenseLayer` is\n",
    "// made of parameters that should be updated during training. See the\n",
    "// [Parameter Update Design](https://github.com/tensorflow/swift/blob/master/proposals/ParameterUpdate.md)\n",
    "// for more information.\n",
    "\n",
    "// ==== Define a neural network model ====\n",
    "// Next, let's use `DenseLayer` to define a nerual network model for the iris classification problem:\n",
    "\n",
    "let hiddenSize: Int32 = 10\n",
    "\n",
    "struct IrisParameters : ParameterAggregate {\n",
    "    var layer1 = DenseLayer(inputSize: 4, outputSize: hiddenSize)\n",
    "    var layer2 = DenseLayer(inputSize: hiddenSize, outputSize: hiddenSize)\n",
    "    var layer3 = DenseLayer(inputSize: hiddenSize, outputSize: 3)\n",
    "}\n",
    "\n",
    "func predictions(for input: Tensor<Float>, using model: IrisParameters) -> Tensor<Float> {\n",
    "    let l1 = relu(predictions(for: input, using: model.layer1))\n",
    "    let l2 = relu(predictions(for: l1, using: model.layer2))\n",
    "    return predictions(for: l2, using: model.layer3)\n",
    "}\n",
    "\n",
    "var model = IrisParameters()\n",
    "\n",
    "// ==== Define a loss function ====\n",
    "// See the loss function section later in the tutorial for a description of the loss function.\n",
    "\n",
    "func loss(for input: Tensor<Float>, using model: IrisParameters, labels: Tensor<Int32>) -> Float {\n",
    "    let logits = predictions(for: input, using: model)\n",
    "    return softmaxCrossEntropy(logits: logits, categoricalLabels: labels)\n",
    "}\n",
    "\n",
    "// ==== Take the gradient of the loss function ===\n",
    "// Use Swift's Automatic Differentiation to calculate the\n",
    "// [*gradients*](https://developers.google.com/machine-learning/glossary/#gradient) used to optimize our model.\n",
    "\n",
    "func lossAndGradient(for input: Tensor<Float>, \n",
    "                     using model: IrisParameters,\n",
    "                     labels: Tensor<Int32>) -> (Float, IrisParameters) {\n",
    "    let (loss, (_, modelGrad)) =\n",
    "        #valueAndGradient(loss(for:using:labels:), wrt: .0, .1)(input, model, labels)\n",
    "    return (loss, modelGrad)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wFKnhWCpDSS"
   },
   "source": [
    "### Using the model\n",
    "\n",
    "Let's have a quick look at what this model does to a batch of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "[[0.4127562, 0.65770745, -0.033418607], [0.25443226, 0.38607907, -0.022551399], [0.3204486, 0.515694, -0.021845274], [0.18517557, 0.23990786, -0.079053566], [0.21861815, 0.28789458, -0.08835358]]\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let firstTrainPredictions = predictions(for: firstTrainFeatures, using: model)\n",
    "firstTrainPredictions[0..<5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxyXOhwVr5S3"
   },
   "source": [
    "Here, each example returns a [logit](https://developers.google.com/machine-learning/crash-course/glossary#logit) for each class. \n",
    "\n",
    "To convert these logits to a probability for each class, use the [softmax](https://developers.google.com/machine-learning/crash-course/glossary#softmax) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_tRwHZmTNTX2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "[[0.079233155, 0.10122504, 0.050714917], [0.0676313, 0.07714739, 0.05126905], [0.072246745, 0.08782381, 0.051305264], [0.063105896, 0.0666561, 0.048452556], [0.065252006, 0.06993269, 0.04800404]]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(firstTrainPredictions[0..<5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRZmchElo481"
   },
   "source": [
    "Taking the `argmax` across classes gives us the predicted class index. But, the model hasn't been trained yet, so these aren't good predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-Jzm_GoErz8B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\r\n",
      "    Labels: [2, 1, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 1, 2, 1, 1, 1, 1]\r\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: \\(firstTrainPredictions.argmax(squeezingAxis: 1))\")\n",
    "print(\"    Labels: \\(firstTrainLabels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vzq2E5J2QMtw"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "*[Training](https://developers.google.com/machine-learning/crash-course/glossary#training)* is the stage of machine learning when the model is gradually optimized, or the model *learns* the dataset. The goal is to learn enough about the structure of the training dataset to make predictions about unseen data. If you learn *too much* about the training dataset, then the predictions only work for the data it has seen and will not be generalizable. This problem is called *[overfitting](https://developers.google.com/machine-learning/crash-course/glossary#overfitting)*â€”it's like memorizing the answers instead of understanding how to solve a problem.\n",
    "\n",
    "The iris classification problem is an example of *[supervised machine learning](https://developers.google.com/machine-learning/glossary/#supervised_machine_learning)*: the model is trained from examples that contain labels. In *[unsupervised machine learning](https://developers.google.com/machine-learning/glossary/#unsupervised_machine_learning)*, the examples don't contain labels. Instead, the model typically finds patterns among the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaKp8aEjKX6B"
   },
   "source": [
    "### Define the loss and gradient function\n",
    "\n",
    "Both training and evaluation stages need to calculate the model's *[loss](https://developers.google.com/machine-learning/crash-course/glossary#loss)*. This measures how off a model's predictions are from the desired label, in other words, how bad the model is performing. We want to minimize, or optimize, this value.\n",
    "\n",
    "Our model will calculate its loss using the `softmaxCrossEntropy` function which takes the model's class probability predictions and the desired label, and returns the average loss across the examples. See the definition of `loss` in the model section above.\n",
    "\n",
    "Let's calculate the loss for the current untrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tMAT4DcMPwI-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 1.168208\r\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss test: \\(loss(for: firstTrainFeatures, using: model, labels: firstTrainLabels))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOxFimtlKruu"
   },
   "source": [
    "### Gradient descent\n",
    "\n",
    "Gradient descent applies the computed gradients to the model's variables to minimize the `loss` function. You can think of the loss function as a curved surface (see Figure 3) and we want to find its lowest point by walking around. The gradients point in the direction of steepest ascentâ€”so we'll travel the opposite way and move down the hill. By iteratively calculating the loss and gradient for each batch, we'll adjust the model during training. Gradually, the model will find the best combination of weights and bias to minimize loss. And the lower the loss, the better the model's predictions.\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\"\n",
    "         alt=\"Optimization algorithms visualized over time in 3D space.\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 3.</b> Optimization algorithms visualized over time in 3D space. (Source: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, MIT License)<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkUd6UiZa_dF"
   },
   "source": [
    "Let's set a learning rate for gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8xxi2NNGKwG_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "let learningRate: Float = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJVRZ0hP52ZB"
   },
   "source": [
    "We'll use this to calculate a single gradient descent step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rxRNTFVe56RG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 1.168208\r\n"
     ]
    }
   ],
   "source": [
    "let (loss, grads) = lossAndGradient(for: firstTrainFeatures, using: model, labels: firstTrainLabels)\n",
    "print(\"Initial Loss: \\(loss)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the `model.update(withGradients:)` method to iterate over all the model parameters and apply gradient descent to them, where `param` is the parameter and where `grad` is the gradient along that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Loss: 1.1378695\r\n"
     ]
    }
   ],
   "source": [
    "model.update(withGradients: grads) { param, grad in\n",
    "    param -= learningRate * grad\n",
    "}\n",
    "print(\"Next Loss: \\(loss(for: firstTrainFeatures, using: model, labels: firstTrainLabels))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the above step repeatedly, you should expect the loss to go down gradually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Y2VSELvwAvW"
   },
   "source": [
    "### Training loop\n",
    "\n",
    "With all the pieces in place, the model is ready for training! A training loop feeds the dataset examples into the model to help it make better predictions. The following code block sets up these training steps:\n",
    "\n",
    "1. Iterate each *epoch*. An epoch is one pass through the dataset.\n",
    "2. Within an epoch, iterate over each example in the training `Dataset` grabbing its *features* (`x`) and *label* (`y`).\n",
    "3. Using the example's features, make a prediction and compare it with the label. Measure the inaccuracy of the prediction and use that to calculate the model's loss and gradients.\n",
    "4. Use gradient descent to update the model's variables.\n",
    "5. Keep track of some stats for visualization.\n",
    "6. Repeat for each epoch.\n",
    "\n",
    "The `numEpochs` variable is the number of times to loop over the dataset collection. Counter-intuitively, training a model longer does not guarantee a better model. `numEpochs` is a *[hyperparameter](https://developers.google.com/machine-learning/glossary/#hyperparameter)* that you can tune. Choosing the right number usually requires both experience and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AIgulGRUhpto"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "let numEpochs = 201\n",
    "var trainAccuracyResults: [Float] = []\n",
    "var trainLossResults: [Float] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"TutorialDatasetCSVAPI.swift\"\n",
    "@inlinable\n",
    "func trainDataset() -> Dataset<(Tensor<Float>, Tensor<Int32>)> {\n",
    "    return Dataset(\n",
    "        contentsOfCSVFile: trainDataFilename, hasHeader: true,\n",
    "        featureColumns: [0, 1, 2, 3], labelColumns: [4]\n",
    "    ).batched(batchSize)\n",
    "}\n",
    "\n",
    "func accuracy(predictions: Tensor<Int32>, truths: Tensor<Int32>) -> Float {\n",
    "    return Tensor<Float>(predictions.elementsEqual(truths)).mean()\n",
    "}\n",
    "\n",
    "for epoch in 0..<numEpochs {\n",
    "    var epochLoss: Float = 0\n",
    "    var epochAccuracy: Float = 0\n",
    "    var batchCount: Int = 0\n",
    "    for (x, y) in trainDataset() {       \n",
    "        let (loss, grad) = lossAndGradient(for: x, using: model, labels: y)\n",
    "        model.update(withGradients: grad) { $0 -= learningRate * $1 }\n",
    "        \n",
    "        let logits = predictions(for: x, using: model)\n",
    "        epochAccuracy += accuracy(predictions: logits.argmax(squeezingAxis: 1), truths: y)\n",
    "        epochLoss += loss\n",
    "        batchCount += 1\n",
    "    }\n",
    "    epochAccuracy /= Float(batchCount)\n",
    "    epochLoss /= Float(batchCount)\n",
    "    trainAccuracyResults.append(epochAccuracy)\n",
    "    trainLossResults.append(epochLoss)\n",
    "    if epoch % 50 == 0 {\n",
    "        print(\"Epoch \\(epoch): Loss: \\(epochLoss), Accuracy: \\(epochAccuracy)\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FQHVUnm_rjw"
   },
   "source": [
    "### Visualize the loss function over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3wdbmtLVTyr"
   },
   "source": [
    "While it's helpful to print out the model's training progress, it's often *more* helpful to see this progress. We can create basic charts using Python's `matplotlib` module.\n",
    "\n",
    "Interpreting these charts takes some experience, but you really want to see the *loss* go down and the *accuracy* go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "agjvNd2iUGFn"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize: [12, 8])\n",
    "\n",
    "let accuracyAxes = plt.subplot(2, 1, 1)\n",
    "accuracyAxes.set_ylabel(\"Accuracy\")\n",
    "accuracyAxes.plot(trainAccuracyResults)\n",
    "\n",
    "let lossAxes = plt.subplot(2, 1, 2)\n",
    "lossAxes.set_ylabel(\"Loss\")\n",
    "lossAxes.set_xlabel(\"Epoch\")\n",
    "lossAxes.plot(trainLossResults)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the y-axes of the graphs are not zero-based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zg8GoMZhLpGH"
   },
   "source": [
    "## Evaluate the model's effectiveness\n",
    "\n",
    "Now that the model is trained, we can get some statistics on its performance.\n",
    "\n",
    "*Evaluating* means determining how effectively the model makes predictions. To determine the model's effectiveness at iris classification, pass some sepal and petal measurements to the model and ask the model to predict what iris species they represent. Then compare the model's prediction against the actual label.  For example, a model that picked the correct species on half the input examples has an *[accuracy](https://developers.google.com/machine-learning/glossary/#accuracy)* of `0.5`. Figure 4 shows a slightly more effective model, getting 4 out of 5 predictions correct at 80% accuracy:\n",
    "\n",
    "<table cellpadding=\"8\" border=\"0\">\n",
    "  <colgroup>\n",
    "    <col span=\"4\" >\n",
    "    <col span=\"1\" bgcolor=\"lightblue\">\n",
    "    <col span=\"1\" bgcolor=\"lightgreen\">\n",
    "  </colgroup>\n",
    "  <tr bgcolor=\"lightgray\">\n",
    "    <th colspan=\"4\">Example features</th>\n",
    "    <th colspan=\"1\">Label</th>\n",
    "    <th colspan=\"1\" >Model prediction</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5.9</td><td>3.0</td><td>4.3</td><td>1.5</td><td align=\"center\">1</td><td align=\"center\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6.9</td><td>3.1</td><td>5.4</td><td>2.1</td><td align=\"center\">2</td><td align=\"center\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td align=\"center\">0</td><td align=\"center\">0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6.0</td> <td>3.4</td> <td>4.5</td> <td>1.6</td> <td align=\"center\">1</td><td align=\"center\" bgcolor=\"red\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5.5</td><td>2.5</td><td>4.0</td><td>1.3</td><td align=\"center\">1</td><td align=\"center\">1</td>\n",
    "  </tr>\n",
    "  <tr><td align=\"center\" colspan=\"6\">\n",
    "    <b>Figure 4.</b> An iris classifier that is 80% accurate.<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-EvK7hGL0d8"
   },
   "source": [
    "### Setup the test dataset\n",
    "\n",
    "Evaluating the model is similar to training the model. The biggest difference is the examples come from a separate *[test set](https://developers.google.com/machine-learning/crash-course/glossary#test_set)* rather than the training set. To fairly assess a model's effectiveness, the examples used to evaluate a model must be different from the examples used to train the model.\n",
    "\n",
    "The setup for the test `Dataset` is similar to the setup for training `Dataset`. Download the test set from http://download.tensorflow.org/data/iris_training.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SRMWCu30bnxH"
   },
   "outputs": [],
   "source": [
    "let urllib = Python.import(\"urllib\")\n",
    "let downloadResult = urllib.urlretrieve(\"http://download.tensorflow.org/data/iris_test.csv\",\n",
    "                                        \"iris_test.csv\")\n",
    "let testDataFilename = String(downloadResult[0])!\n",
    "testDataFilename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now load it into a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"TutorialDatasetCSVAPI.swift\"\n",
    "@inlinable\n",
    "func testDataset() -> Dataset<(Tensor<Float>, Tensor<Int32>)> {\n",
    "    return Dataset(\n",
    "        contentsOfCSVFile: testDataFilename, hasHeader: true,\n",
    "        featureColumns: [0, 1, 2, 3], labelColumns: [4]\n",
    "    ).batched(batchSize)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFuOKXJdMAdm"
   },
   "source": [
    "### Evaluate the model on the test dataset\n",
    "\n",
    "Unlike the training stage, the model only evaluates a single [epoch](https://developers.google.com/machine-learning/glossary/#epoch) of the test data. In the following code cell, we iterate over each example in the test set and compare the model's prediction against the actual label. This is used to measure the model's accuracy across the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"TutorialDatasetCSVAPI.swift\"\n",
    "@inlinable\n",
    "func testDataset() -> Dataset<(Tensor<Float>, Tensor<Int32>)> {\n",
    "    return Dataset(\n",
    "        contentsOfCSVFile: testDataFilename, hasHeader: true,\n",
    "        featureColumns: [0, 1, 2, 3], labelColumns: [4]\n",
    "    ).batched(batchSize)\n",
    "}\n",
    "\n",
    "for (testFeatures, testLabels) in testDataset() {\n",
    "    let logits = predictions(for: testFeatures, using: model)\n",
    "    let predictions = logits.argmax(squeezingAxis: 1)\n",
    "    print(\"Test batch accuracy: \\(accuracy(predictions: predictions, truths: testLabels))\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcKEZMtCOeK-"
   },
   "source": [
    "We can see on the first batch, for example, the model is usually correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uNwt2eMeOane"
   },
   "outputs": [],
   "source": [
    "%include \"TutorialDatasetCSVAPI.swift\"\n",
    "@inlinable\n",
    "func testDataset() -> Dataset<(Tensor<Float>, Tensor<Int32>)> {\n",
    "    return Dataset(\n",
    "        contentsOfCSVFile: testDataFilename, hasHeader: true,\n",
    "        featureColumns: [0, 1, 2, 3], labelColumns: [4]\n",
    "    ).batched(batchSize)\n",
    "}\n",
    "\n",
    "let (firstTestBatchFeatures, firstTestBatchLabels) = testDataset().first()!\n",
    "let firstTestBatchLogits = predictions(for: firstTestBatchFeatures, using: model)\n",
    "let firstTestBatchPredictions = firstTestBatchLogits.argmax(squeezingAxis: 1)\n",
    "\n",
    "print(firstTestBatchPredictions)\n",
    "print(firstTestBatchLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Li2r1tYvW7S"
   },
   "source": [
    "## Use the trained model to make predictions\n",
    "\n",
    "We've trained a model and demonstrated that it's goodâ€”but not perfectâ€”at classifying iris species. Now let's use the trained model to make some predictions on [unlabeled examples](https://developers.google.com/machine-learning/glossary/#unlabeled_example); that is, on examples that contain features but not a label.\n",
    "\n",
    "In real-life, the unlabeled examples could come from lots of different sources including apps, CSV files, and data feeds. For now, we're going to manually provide three unlabeled examples to predict their labels. Recall, the label numbers are mapped to a named representation as:\n",
    "\n",
    "* `0`: Iris setosa\n",
    "* `1`: Iris versicolor\n",
    "* `2`: Iris virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let unlabeledDataset: Tensor<Float> =\n",
    "    [[5.1, 3.3, 1.7, 0.5],\n",
    "     [5.9, 3.0, 4.2, 1.5],\n",
    "     [6.9, 3.1, 5.4, 2.1]]\n",
    "\n",
    "let unlabeledDatasetPredictions = predictions(for: unlabeledDataset, using: model)\n",
    "\n",
    "for i in 0..<unlabeledDatasetPredictions.shape[0] {\n",
    "    let logits = unlabeledDatasetPredictions[i]\n",
    "    let classIdx = logits.argmax()\n",
    "    print(\"Example \\(i) prediction: \\(classNames[Int(classIdx)]) (\\(softmax(logits)))\")\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Custom training: walkthrough",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
